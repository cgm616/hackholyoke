{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the csv just as in `dataset.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data_file_name = \"../dataset/fer2013.csv\"\n",
    "raw_data = pd.read_csv(raw_data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "train_data = raw_data[raw_data[\"Usage\"] == \"Training\"]\n",
    "train_expected = keras.utils.to_categorical(train_data[\"emotion\"], num_classes=7, dtype='int32')\n",
    "first_test_data = raw_data[raw_data[\"Usage\"] == \"PrivateTest\"]\n",
    "first_test_expected = keras.utils.to_categorical(first_test_data[\"emotion\"], num_classes=7, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pixel_row(row):\n",
    "    split = row.split(\" \")\n",
    "    pixels = np.array(split, 'float32')\n",
    "    pixels /= 255\n",
    "    return pixels.reshape(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels = train_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_pixels = first_test_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_input_layer(array_input):\n",
    "    vg_input = np.empty([int(len(array_input)), 48, 48, 3])\n",
    "    for index, item in enumerate(vg_input):\n",
    "        item[:, :, 0] = array_input[index]\n",
    "        item[:, :, 1] = array_input[index]\n",
    "        item[:, :, 2] = array_input[index]\n",
    "    return vg_input\n",
    "\n",
    "train_pixels_duplicated = duplicate_input_layer(train_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load up a pre-trained neural network from `keras`, a high-level API on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_features = vgg16.predict(train_pixels_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_map = np.empty([len(train_output_features), 512])\n",
    "for idx_pic, picture in enumerate(train_output_features):\n",
    "    train_feature_map[idx_pic] = picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our own top-level network to load on top of VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "topLayerModel = Sequential()\n",
    "topLayerModel.add(Dense(256, input_shape=(512,), activation='relu'))\n",
    "topLayerModel.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dropout(0.5))\n",
    "topLayerModel.add(Dense(128, input_shape=(256,), activation='relu'))\n",
    "topLayerModel.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "adamax = optimizers.Adamax()\n",
    "\n",
    "topLayerModel.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adamax, metrics=['accuracy'])\n",
    "\n",
    "topLayerModel.fit(train_feature_map, train_expected,\n",
    "          validation_data=(train_feature_map, train_expected),\n",
    "          epoch=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
