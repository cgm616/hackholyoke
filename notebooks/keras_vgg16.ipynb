{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the csv just as in `dataset.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data_file_name = \"../dataset/fer2013.csv\"\n",
    "raw_data = pd.read_csv(raw_data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we separate and clean the data a little bit. First, we create an array of only the training data. Then, we create an array of only the private test data (referred to in the code with the prefix `first_test`). The `reset_index` call re-aligns the `first_test_data` to index from 0 instead of wherever it starts in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_data[raw_data[\"Usage\"] == \"Training\"]\n",
    "\n",
    "first_test_data = raw_data[raw_data[\"Usage\"] == \"PrivateTest\"]\n",
    "first_test_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "train_expected = keras.utils.to_categorical(train_data[\"emotion\"], num_classes=7, dtype='int32')\n",
    "first_test_expected = keras.utils.to_categorical(first_test_data[\"emotion\"], num_classes=7, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pixel_row(row):\n",
    "    split = row.split(\" \")\n",
    "    pixels = np.array(split, 'float32')\n",
    "    pixels /= 255\n",
    "    return pixels.reshape(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels = train_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_pixels = first_test_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_input_layer(array_input):\n",
    "    vg_input = np.empty([int(len(array_input)), 48, 48, 3])\n",
    "    for index, item in enumerate(vg_input):\n",
    "        item[:, :, 0] = array_input[index]\n",
    "        item[:, :, 1] = array_input[index]\n",
    "        item[:, :, 2] = array_input[index]\n",
    "    return vg_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels_duplicated = duplicate_input_layer(train_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_pixels_duplicated = duplicate_input_layer(first_test_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load up a pre-trained neural network from `keras`, a high-level API on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet', pooling='avr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_features = vgg16.predict(train_pixels_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_output_features = vgg16.predict(first_test_pixels_duplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our own top-level network to load on top of VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Reshape\n",
    "\n",
    "top_layer_model = Sequential()\n",
    "top_layer_model.add(Reshape((512,), input_shape=(1, 1, 512)))\n",
    "top_layer_model.add(Dense(256, input_shape=(512,), activation='relu'))\n",
    "top_layer_model.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "top_layer_model.add(Dropout(0.5))\n",
    "top_layer_model.add(Dense(128, input_shape=(256,), activation='relu'))\n",
    "top_layer_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 28709 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 2s 85us/step - loss: 1.6675 - accuracy: 0.3347 - val_loss: 1.5775 - val_accuracy: 0.3876\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 2s 81us/step - loss: 1.5816 - accuracy: 0.3852 - val_loss: 1.5401 - val_accuracy: 0.4029\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 2s 76us/step - loss: 1.5414 - accuracy: 0.4043 - val_loss: 1.4856 - val_accuracy: 0.4300\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 2s 79us/step - loss: 1.5089 - accuracy: 0.4219 - val_loss: 1.4617 - val_accuracy: 0.4407\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 2s 75us/step - loss: 1.4811 - accuracy: 0.4324 - val_loss: 1.4421 - val_accuracy: 0.4452\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 2s 78us/step - loss: 1.4496 - accuracy: 0.4440 - val_loss: 1.3911 - val_accuracy: 0.4711\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 2s 74us/step - loss: 1.4238 - accuracy: 0.4565 - val_loss: 1.3695 - val_accuracy: 0.4808\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 2s 74us/step - loss: 1.3968 - accuracy: 0.4703 - val_loss: 1.3374 - val_accuracy: 0.4917\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 2s 79us/step - loss: 1.3662 - accuracy: 0.4823 - val_loss: 1.2912 - val_accuracy: 0.5103\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 2s 80us/step - loss: 1.3391 - accuracy: 0.4944 - val_loss: 1.2623 - val_accuracy: 0.5282\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 2s 80us/step - loss: 1.3102 - accuracy: 0.5068 - val_loss: 1.2196 - val_accuracy: 0.5468\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 2s 80us/step - loss: 1.2826 - accuracy: 0.5157 - val_loss: 1.1911 - val_accuracy: 0.5586\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 2s 78us/step - loss: 1.2539 - accuracy: 0.5279 - val_loss: 1.1733 - val_accuracy: 0.5624\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 2s 74us/step - loss: 1.2251 - accuracy: 0.5426 - val_loss: 1.1322 - val_accuracy: 0.5834\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 2s 76us/step - loss: 1.2006 - accuracy: 0.5510 - val_loss: 1.1028 - val_accuracy: 0.6004\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 2s 71us/step - loss: 1.1696 - accuracy: 0.5662 - val_loss: 1.0696 - val_accuracy: 0.6054\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 2s 77us/step - loss: 1.1422 - accuracy: 0.5750 - val_loss: 1.0330 - val_accuracy: 0.6269\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 2s 80us/step - loss: 1.1093 - accuracy: 0.5878 - val_loss: 1.0121 - val_accuracy: 0.6296\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 2s 77us/step - loss: 1.0850 - accuracy: 0.5985 - val_loss: 0.9950 - val_accuracy: 0.6361\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 2s 73us/step - loss: 1.0583 - accuracy: 0.6089 - val_loss: 0.9543 - val_accuracy: 0.6539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ad52b850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "adamax = optimizers.Adamax()\n",
    "\n",
    "top_layer_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adamax, metrics=['accuracy'])\n",
    "\n",
    "top_layer_model.fit(train_output_features, train_expected,\n",
    "          validation_data=(train_output_features, train_expected),\n",
    "          epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 0s 23us/step\n",
      "After top_layer_model training (test set): [1.5379799089580566, 0.46865421533584595]\n"
     ]
    }
   ],
   "source": [
    "score = top_layer_model.evaluate(first_test_output_features, first_test_expected, batch_size=32)\n",
    "\n",
    "print(\"After top_layer_model training (test set): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "inputs = Input(shape=(48, 48, 3))\n",
    "vg_output = vgg16(inputs)\n",
    "\n",
    "# TODO: the 'pooling' argument of the VGG16 model is important for this to work otherwise you will have to  squash\n",
    "# output from (?, 1, 1, 512) to (?, 512)\n",
    "\n",
    "model_predictions = top_layer_model(vg_output)\n",
    "final_model = Model(inputs=inputs, outputs=model_predictions)\n",
    "final_model.compile(loss='categorical_crossentropy',optimizer=adamax, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 195s 7ms/step\n",
      "Sanity check - final_model (train score): [0.9542508401144568, 0.6538715958595276]\n"
     ]
    }
   ],
   "source": [
    "final_model_score = final_model.evaluate(train_pixels_duplicated, train_expected, batch_size=32)\n",
    "print(\"Sanity check - final_model (train score): {}\".format(final_model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 25s 7ms/step\n",
      "Sanity check - final_model (test score): [1.5379799089580566, 0.46865421533584595]\n"
     ]
    }
   ],
   "source": [
    "final_model_score = final_model.evaluate(first_test_pixels_duplicated, first_test_expected, batch_size=32)\n",
    "print(\"Sanity check - final_model (test score): {}\".format(final_model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
