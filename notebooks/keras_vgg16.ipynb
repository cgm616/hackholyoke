{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the csv just as in `dataset.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data_file_name = \"../dataset/fer2013.csv\"\n",
    "raw_data = pd.read_csv(raw_data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we separate and clean the data a little bit. First, we create an array of only the training data. Then, we create an array of only the private test data (referred to in the code with the prefix `first_test`). The `reset_index` call re-aligns the `first_test_data` to index from 0 instead of wherever it starts in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_data[raw_data[\"Usage\"] == \"Training\"]\n",
    "\n",
    "first_test_data = raw_data[raw_data[\"Usage\"] == \"PrivateTest\"]\n",
    "first_test_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "train_expected = keras.utils.to_categorical(train_data[\"emotion\"], num_classes=7, dtype='int32')\n",
    "first_test_expected = keras.utils.to_categorical(first_test_data[\"emotion\"], num_classes=7, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pixel_row(row):\n",
    "    split = row.split(\" \")\n",
    "    pixels = np.array(split, 'float32')\n",
    "    pixels /= 255\n",
    "    return pixels.reshape(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels = train_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_pixels = first_test_data[\"pixels\"].apply(process_pixel_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_input_layer(array_input):\n",
    "    vg_input = np.empty([int(len(array_input)), 48, 48, 3])\n",
    "    for index, item in enumerate(vg_input):\n",
    "        item[:, :, 0] = array_input[index]\n",
    "        item[:, :, 1] = array_input[index]\n",
    "        item[:, :, 2] = array_input[index]\n",
    "    return vg_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels_duplicated = duplicate_input_layer(train_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_pixels_duplicated = duplicate_input_layer(first_test_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load up a pre-trained neural network from `keras`, a high-level API on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16(include_top=False, input_shape=(48, 48, 3), weights='imagenet', pooling='avr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_features = vgg16.predict(train_pixels_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test_output_features = vgg16.predict(first_test_pixels_duplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create our own top-level network to load on top of VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Reshape\n",
    "\n",
    "top_layer_model = Sequential()\n",
    "top_layer_model.add(Reshape((512,), input_shape=(1, 1, 512)))\n",
    "top_layer_model.add(Dense(256, input_shape=(512,), activation='relu'))\n",
    "top_layer_model.add(Dense(256, input_shape=(256,), activation='relu'))\n",
    "top_layer_model.add(Dropout(0.5))\n",
    "top_layer_model.add(Dense(128, input_shape=(256,), activation='relu'))\n",
    "top_layer_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "adamax = optimizers.Adamax()\n",
    "\n",
    "top_layer_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adamax, metrics=['accuracy'])\n",
    "\n",
    "top_layer_model.fit(train_output_features, train_expected,\n",
    "          validation_data=(train_output_features, train_expected),\n",
    "          epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = top_layer_model.evaluate(first_test_output_features, first_test_expected, batch_size=32)\n",
    "\n",
    "print(\"After top_layer_model training (test set): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "inputs = Input(shape=(48, 48, 3))\n",
    "vg_output = vgg16(inputs)\n",
    "\n",
    "# TODO: the 'pooling' argument of the VGG16 model is important for this to work otherwise you will have to  squash\n",
    "# output from (?, 1, 1, 512) to (?, 512)\n",
    "\n",
    "model_predictions = top_layer_model(vg_output)\n",
    "final_model = Model(inputs=inputs, outputs=model_predictions)\n",
    "final_model.compile(loss='categorical_crossentropy',optimizer=adamax, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_score = final_model.evaluate(train_pixels_duplicated, train_expected, batch_size=32)\n",
    "print(\"Sanity check - final_model (train score): {}\".format(final_model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_score = final_model.evaluate(first_test_pixels_duplicated, first_test_expected, batch_size=32)\n",
    "print(\"Sanity check - final_model (test score): {}\".format(final_model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
